[
    {
        "epoch": 0.007942811755361398,
        "grad_norm": 2.436164617538452,
        "learning_rate": 2.5e-05,
        "loss": 0.5209,
        "step": 10
    },
    {
        "epoch": 0.015885623510722795,
        "grad_norm": 1.8197298049926758,
        "learning_rate": 5e-05,
        "loss": 0.5857,
        "step": 20
    },
    {
        "epoch": 0.023828435266084195,
        "grad_norm": 1.9272911548614502,
        "learning_rate": 4.979983987189752e-05,
        "loss": 0.5415,
        "step": 30
    },
    {
        "epoch": 0.03177124702144559,
        "grad_norm": 1.3885077238082886,
        "learning_rate": 4.959967974379504e-05,
        "loss": 0.5778,
        "step": 40
    },
    {
        "epoch": 0.03971405877680699,
        "grad_norm": 1.7161779403686523,
        "learning_rate": 4.9399519615692554e-05,
        "loss": 0.5867,
        "step": 50
    },
    {
        "epoch": 0.04765687053216839,
        "grad_norm": 1.5740710496902466,
        "learning_rate": 4.9199359487590074e-05,
        "loss": 0.5973,
        "step": 60
    },
    {
        "epoch": 0.05559968228752978,
        "grad_norm": 1.6345305442810059,
        "learning_rate": 4.8999199359487594e-05,
        "loss": 0.5436,
        "step": 70
    },
    {
        "epoch": 0.06354249404289118,
        "grad_norm": 1.5656781196594238,
        "learning_rate": 4.879903923138511e-05,
        "loss": 0.5657,
        "step": 80
    },
    {
        "epoch": 0.07148530579825259,
        "grad_norm": 1.567216396331787,
        "learning_rate": 4.859887910328263e-05,
        "loss": 0.5223,
        "step": 90
    },
    {
        "epoch": 0.07942811755361398,
        "grad_norm": 1.2336827516555786,
        "learning_rate": 4.8398718975180146e-05,
        "loss": 0.5536,
        "step": 100
    },
    {
        "epoch": 0.08737092930897537,
        "grad_norm": 1.1499648094177246,
        "learning_rate": 4.8198558847077665e-05,
        "loss": 0.5858,
        "step": 110
    },
    {
        "epoch": 0.09531374106433678,
        "grad_norm": 1.4744092226028442,
        "learning_rate": 4.7998398718975185e-05,
        "loss": 0.5547,
        "step": 120
    },
    {
        "epoch": 0.10325655281969817,
        "grad_norm": 1.3789504766464233,
        "learning_rate": 4.7798238590872704e-05,
        "loss": 0.5202,
        "step": 130
    },
    {
        "epoch": 0.11119936457505956,
        "grad_norm": 1.3711318969726562,
        "learning_rate": 4.759807846277022e-05,
        "loss": 0.5747,
        "step": 140
    },
    {
        "epoch": 0.11914217633042097,
        "grad_norm": 1.663835048675537,
        "learning_rate": 4.739791833466774e-05,
        "loss": 0.6107,
        "step": 150
    },
    {
        "epoch": 0.12708498808578236,
        "grad_norm": 1.3286409378051758,
        "learning_rate": 4.7197758206565256e-05,
        "loss": 0.5459,
        "step": 160
    },
    {
        "epoch": 0.13502779984114377,
        "grad_norm": 1.1853511333465576,
        "learning_rate": 4.6997598078462776e-05,
        "loss": 0.555,
        "step": 170
    },
    {
        "epoch": 0.14297061159650518,
        "grad_norm": 1.3209635019302368,
        "learning_rate": 4.679743795036029e-05,
        "loss": 0.5778,
        "step": 180
    },
    {
        "epoch": 0.15091342335186655,
        "grad_norm": 1.1492092609405518,
        "learning_rate": 4.659727782225781e-05,
        "loss": 0.5394,
        "step": 190
    },
    {
        "epoch": 0.15885623510722796,
        "grad_norm": 1.278281807899475,
        "learning_rate": 4.639711769415533e-05,
        "loss": 0.6196,
        "step": 200
    },
    {
        "epoch": 0.16679904686258937,
        "grad_norm": 1.4038288593292236,
        "learning_rate": 4.619695756605285e-05,
        "loss": 0.5455,
        "step": 210
    },
    {
        "epoch": 0.17474185861795075,
        "grad_norm": 1.1495213508605957,
        "learning_rate": 4.599679743795036e-05,
        "loss": 0.5843,
        "step": 220
    },
    {
        "epoch": 0.18268467037331215,
        "grad_norm": 1.3475130796432495,
        "learning_rate": 4.579663730984788e-05,
        "loss": 0.5152,
        "step": 230
    },
    {
        "epoch": 0.19062748212867356,
        "grad_norm": 1.3088817596435547,
        "learning_rate": 4.55964771817454e-05,
        "loss": 0.5101,
        "step": 240
    },
    {
        "epoch": 0.19857029388403494,
        "grad_norm": 1.1610214710235596,
        "learning_rate": 4.539631705364292e-05,
        "loss": 0.4895,
        "step": 250
    },
    {
        "epoch": 0.20651310563939634,
        "grad_norm": 1.355420470237732,
        "learning_rate": 4.519615692554043e-05,
        "loss": 0.5549,
        "step": 260
    },
    {
        "epoch": 0.21445591739475775,
        "grad_norm": 1.1647157669067383,
        "learning_rate": 4.499599679743795e-05,
        "loss": 0.5022,
        "step": 270
    },
    {
        "epoch": 0.22239872915011913,
        "grad_norm": 1.3888498544692993,
        "learning_rate": 4.479583666933547e-05,
        "loss": 0.481,
        "step": 280
    },
    {
        "epoch": 0.23034154090548054,
        "grad_norm": 1.2551177740097046,
        "learning_rate": 4.459567654123299e-05,
        "loss": 0.4939,
        "step": 290
    },
    {
        "epoch": 0.23828435266084194,
        "grad_norm": 1.3180012702941895,
        "learning_rate": 4.4395516413130504e-05,
        "loss": 0.46,
        "step": 300
    },
    {
        "epoch": 0.24622716441620335,
        "grad_norm": 1.2847729921340942,
        "learning_rate": 4.419535628502802e-05,
        "loss": 0.4588,
        "step": 310
    },
    {
        "epoch": 0.2541699761715647,
        "grad_norm": 1.4712706804275513,
        "learning_rate": 4.399519615692554e-05,
        "loss": 0.5499,
        "step": 320
    },
    {
        "epoch": 0.2621127879269261,
        "grad_norm": 1.3105192184448242,
        "learning_rate": 4.379503602882306e-05,
        "loss": 0.5394,
        "step": 330
    },
    {
        "epoch": 0.27005559968228754,
        "grad_norm": 1.266788125038147,
        "learning_rate": 4.3594875900720575e-05,
        "loss": 0.4958,
        "step": 340
    },
    {
        "epoch": 0.2779984114376489,
        "grad_norm": 1.2659505605697632,
        "learning_rate": 4.3394715772618095e-05,
        "loss": 0.5021,
        "step": 350
    },
    {
        "epoch": 0.28594122319301035,
        "grad_norm": 1.1134676933288574,
        "learning_rate": 4.3194555644515615e-05,
        "loss": 0.5152,
        "step": 360
    },
    {
        "epoch": 0.29388403494837173,
        "grad_norm": 1.2601792812347412,
        "learning_rate": 4.2994395516413134e-05,
        "loss": 0.5001,
        "step": 370
    },
    {
        "epoch": 0.3018268467037331,
        "grad_norm": 1.3898144960403442,
        "learning_rate": 4.279423538831065e-05,
        "loss": 0.4568,
        "step": 380
    },
    {
        "epoch": 0.30976965845909454,
        "grad_norm": 1.1069005727767944,
        "learning_rate": 4.2594075260208167e-05,
        "loss": 0.4918,
        "step": 390
    },
    {
        "epoch": 0.3177124702144559,
        "grad_norm": 1.3284567594528198,
        "learning_rate": 4.2393915132105686e-05,
        "loss": 0.4455,
        "step": 400
    },
    {
        "epoch": 0.3256552819698173,
        "grad_norm": 1.1456942558288574,
        "learning_rate": 4.2193755004003206e-05,
        "loss": 0.4809,
        "step": 410
    },
    {
        "epoch": 0.33359809372517873,
        "grad_norm": 1.0553053617477417,
        "learning_rate": 4.199359487590072e-05,
        "loss": 0.4994,
        "step": 420
    },
    {
        "epoch": 0.3415409054805401,
        "grad_norm": 1.4110441207885742,
        "learning_rate": 4.179343474779824e-05,
        "loss": 0.4545,
        "step": 430
    },
    {
        "epoch": 0.3494837172359015,
        "grad_norm": 0.9994431138038635,
        "learning_rate": 4.159327461969576e-05,
        "loss": 0.4625,
        "step": 440
    },
    {
        "epoch": 0.3574265289912629,
        "grad_norm": 1.3661673069000244,
        "learning_rate": 4.139311449159328e-05,
        "loss": 0.4626,
        "step": 450
    },
    {
        "epoch": 0.3653693407466243,
        "grad_norm": 1.4360769987106323,
        "learning_rate": 4.119295436349079e-05,
        "loss": 0.4611,
        "step": 460
    },
    {
        "epoch": 0.3733121525019857,
        "grad_norm": 1.2804917097091675,
        "learning_rate": 4.099279423538831e-05,
        "loss": 0.4523,
        "step": 470
    },
    {
        "epoch": 0.3812549642573471,
        "grad_norm": 1.114704966545105,
        "learning_rate": 4.079263410728583e-05,
        "loss": 0.4485,
        "step": 480
    },
    {
        "epoch": 0.3891977760127085,
        "grad_norm": 1.4311933517456055,
        "learning_rate": 4.059247397918335e-05,
        "loss": 0.4152,
        "step": 490
    },
    {
        "epoch": 0.3971405877680699,
        "grad_norm": 1.2863363027572632,
        "learning_rate": 4.039231385108086e-05,
        "loss": 0.4622,
        "step": 500
    },
    {
        "epoch": 0.4050833995234313,
        "grad_norm": 1.3621119260787964,
        "learning_rate": 4.019215372297839e-05,
        "loss": 0.5046,
        "step": 510
    },
    {
        "epoch": 0.4130262112787927,
        "grad_norm": 1.4260141849517822,
        "learning_rate": 3.99919935948759e-05,
        "loss": 0.412,
        "step": 520
    },
    {
        "epoch": 0.42096902303415407,
        "grad_norm": 1.0998679399490356,
        "learning_rate": 3.979183346677342e-05,
        "loss": 0.4789,
        "step": 530
    },
    {
        "epoch": 0.4289118347895155,
        "grad_norm": 1.2239627838134766,
        "learning_rate": 3.959167333867094e-05,
        "loss": 0.4683,
        "step": 540
    },
    {
        "epoch": 0.4368546465448769,
        "grad_norm": 1.2462080717086792,
        "learning_rate": 3.939151321056846e-05,
        "loss": 0.4508,
        "step": 550
    },
    {
        "epoch": 0.44479745830023826,
        "grad_norm": 1.0835028886795044,
        "learning_rate": 3.919135308246597e-05,
        "loss": 0.4987,
        "step": 560
    },
    {
        "epoch": 0.4527402700555997,
        "grad_norm": 1.298717737197876,
        "learning_rate": 3.899119295436349e-05,
        "loss": 0.4704,
        "step": 570
    },
    {
        "epoch": 0.46068308181096107,
        "grad_norm": 1.1077337265014648,
        "learning_rate": 3.879103282626101e-05,
        "loss": 0.4633,
        "step": 580
    },
    {
        "epoch": 0.4686258935663225,
        "grad_norm": 1.3887616395950317,
        "learning_rate": 3.859087269815853e-05,
        "loss": 0.433,
        "step": 590
    },
    {
        "epoch": 0.4765687053216839,
        "grad_norm": 1.3618254661560059,
        "learning_rate": 3.839071257005605e-05,
        "loss": 0.4424,
        "step": 600
    },
    {
        "epoch": 0.48451151707704526,
        "grad_norm": 1.3188644647598267,
        "learning_rate": 3.8190552441953564e-05,
        "loss": 0.4337,
        "step": 610
    },
    {
        "epoch": 0.4924543288324067,
        "grad_norm": 1.6019033193588257,
        "learning_rate": 3.7990392313851084e-05,
        "loss": 0.3679,
        "step": 620
    },
    {
        "epoch": 0.5003971405877681,
        "grad_norm": 1.4604185819625854,
        "learning_rate": 3.77902321857486e-05,
        "loss": 0.4229,
        "step": 630
    },
    {
        "epoch": 0.5083399523431295,
        "grad_norm": 1.2619537115097046,
        "learning_rate": 3.759007205764612e-05,
        "loss": 0.4113,
        "step": 640
    },
    {
        "epoch": 0.5162827640984908,
        "grad_norm": 1.2320107221603394,
        "learning_rate": 3.7389911929543636e-05,
        "loss": 0.4122,
        "step": 650
    },
    {
        "epoch": 0.5242255758538522,
        "grad_norm": 1.6849889755249023,
        "learning_rate": 3.7189751801441155e-05,
        "loss": 0.4167,
        "step": 660
    },
    {
        "epoch": 0.5321683876092137,
        "grad_norm": 1.5898475646972656,
        "learning_rate": 3.6989591673338675e-05,
        "loss": 0.4175,
        "step": 670
    },
    {
        "epoch": 0.5401111993645751,
        "grad_norm": 1.3679646253585815,
        "learning_rate": 3.6789431545236194e-05,
        "loss": 0.4393,
        "step": 680
    },
    {
        "epoch": 0.5480540111199365,
        "grad_norm": 1.2252612113952637,
        "learning_rate": 3.658927141713371e-05,
        "loss": 0.4544,
        "step": 690
    },
    {
        "epoch": 0.5559968228752978,
        "grad_norm": 1.6308034658432007,
        "learning_rate": 3.638911128903123e-05,
        "loss": 0.4347,
        "step": 700
    },
    {
        "epoch": 0.5639396346306592,
        "grad_norm": 1.5111502408981323,
        "learning_rate": 3.6188951160928746e-05,
        "loss": 0.3668,
        "step": 710
    },
    {
        "epoch": 0.5718824463860207,
        "grad_norm": 1.246030330657959,
        "learning_rate": 3.5988791032826266e-05,
        "loss": 0.3953,
        "step": 720
    },
    {
        "epoch": 0.5798252581413821,
        "grad_norm": 1.3146064281463623,
        "learning_rate": 3.578863090472378e-05,
        "loss": 0.4154,
        "step": 730
    },
    {
        "epoch": 0.5877680698967435,
        "grad_norm": 1.3243309259414673,
        "learning_rate": 3.55884707766213e-05,
        "loss": 0.4091,
        "step": 740
    },
    {
        "epoch": 0.5957108816521048,
        "grad_norm": 1.5080066919326782,
        "learning_rate": 3.538831064851882e-05,
        "loss": 0.4185,
        "step": 750
    },
    {
        "epoch": 0.6036536934074662,
        "grad_norm": 1.0561237335205078,
        "learning_rate": 3.518815052041634e-05,
        "loss": 0.4382,
        "step": 760
    },
    {
        "epoch": 0.6115965051628276,
        "grad_norm": 1.3433588743209839,
        "learning_rate": 3.498799039231385e-05,
        "loss": 0.418,
        "step": 770
    },
    {
        "epoch": 0.6195393169181891,
        "grad_norm": 1.2869808673858643,
        "learning_rate": 3.478783026421137e-05,
        "loss": 0.396,
        "step": 780
    },
    {
        "epoch": 0.6274821286735505,
        "grad_norm": 1.5627669095993042,
        "learning_rate": 3.458767013610889e-05,
        "loss": 0.3683,
        "step": 790
    },
    {
        "epoch": 0.6354249404289118,
        "grad_norm": 1.30561363697052,
        "learning_rate": 3.438751000800641e-05,
        "loss": 0.3424,
        "step": 800
    },
    {
        "epoch": 0.6433677521842732,
        "grad_norm": 1.3004579544067383,
        "learning_rate": 3.418734987990392e-05,
        "loss": 0.4032,
        "step": 810
    },
    {
        "epoch": 0.6513105639396346,
        "grad_norm": 1.4428399801254272,
        "learning_rate": 3.398718975180144e-05,
        "loss": 0.4664,
        "step": 820
    },
    {
        "epoch": 0.659253375694996,
        "grad_norm": 1.3155900239944458,
        "learning_rate": 3.378702962369896e-05,
        "loss": 0.403,
        "step": 830
    },
    {
        "epoch": 0.6671961874503575,
        "grad_norm": 1.616317868232727,
        "learning_rate": 3.358686949559648e-05,
        "loss": 0.3696,
        "step": 840
    },
    {
        "epoch": 0.6751389992057188,
        "grad_norm": 1.3662234544754028,
        "learning_rate": 3.3386709367493994e-05,
        "loss": 0.3548,
        "step": 850
    },
    {
        "epoch": 0.6830818109610802,
        "grad_norm": 1.6354680061340332,
        "learning_rate": 3.318654923939151e-05,
        "loss": 0.4192,
        "step": 860
    },
    {
        "epoch": 0.6910246227164416,
        "grad_norm": 1.046399712562561,
        "learning_rate": 3.298638911128903e-05,
        "loss": 0.426,
        "step": 870
    },
    {
        "epoch": 0.698967434471803,
        "grad_norm": 1.226550817489624,
        "learning_rate": 3.278622898318655e-05,
        "loss": 0.4001,
        "step": 880
    },
    {
        "epoch": 0.7069102462271644,
        "grad_norm": 1.5035814046859741,
        "learning_rate": 3.2586068855084065e-05,
        "loss": 0.4214,
        "step": 890
    },
    {
        "epoch": 0.7148530579825259,
        "grad_norm": 1.2185477018356323,
        "learning_rate": 3.2385908726981585e-05,
        "loss": 0.3462,
        "step": 900
    },
    {
        "epoch": 0.7227958697378872,
        "grad_norm": 1.415152668952942,
        "learning_rate": 3.2185748598879104e-05,
        "loss": 0.4092,
        "step": 910
    },
    {
        "epoch": 0.7307386814932486,
        "grad_norm": 1.3143038749694824,
        "learning_rate": 3.1985588470776624e-05,
        "loss": 0.3962,
        "step": 920
    },
    {
        "epoch": 0.73868149324861,
        "grad_norm": 1.3731045722961426,
        "learning_rate": 3.178542834267414e-05,
        "loss": 0.407,
        "step": 930
    },
    {
        "epoch": 0.7466243050039714,
        "grad_norm": 1.226231336593628,
        "learning_rate": 3.1585268214571657e-05,
        "loss": 0.3698,
        "step": 940
    },
    {
        "epoch": 0.7545671167593329,
        "grad_norm": 1.2881572246551514,
        "learning_rate": 3.1385108086469176e-05,
        "loss": 0.3857,
        "step": 950
    },
    {
        "epoch": 0.7625099285146942,
        "grad_norm": 1.5924081802368164,
        "learning_rate": 3.1184947958366696e-05,
        "loss": 0.34,
        "step": 960
    },
    {
        "epoch": 0.7704527402700556,
        "grad_norm": 1.0135667324066162,
        "learning_rate": 3.098478783026421e-05,
        "loss": 0.3664,
        "step": 970
    },
    {
        "epoch": 0.778395552025417,
        "grad_norm": 1.1356210708618164,
        "learning_rate": 3.0784627702161735e-05,
        "loss": 0.3187,
        "step": 980
    },
    {
        "epoch": 0.7863383637807784,
        "grad_norm": 1.2605525255203247,
        "learning_rate": 3.058446757405925e-05,
        "loss": 0.3027,
        "step": 990
    },
    {
        "epoch": 0.7942811755361397,
        "grad_norm": 1.2470108270645142,
        "learning_rate": 3.0384307445956767e-05,
        "loss": 0.3439,
        "step": 1000
    },
    {
        "epoch": 0.8022239872915012,
        "grad_norm": 1.81675386428833,
        "learning_rate": 3.0184147317854284e-05,
        "loss": 0.3586,
        "step": 1010
    },
    {
        "epoch": 0.8101667990468626,
        "grad_norm": 1.4903415441513062,
        "learning_rate": 2.9983987189751807e-05,
        "loss": 0.3429,
        "step": 1020
    },
    {
        "epoch": 0.818109610802224,
        "grad_norm": 1.3656821250915527,
        "learning_rate": 2.9783827061649323e-05,
        "loss": 0.3543,
        "step": 1030
    },
    {
        "epoch": 0.8260524225575854,
        "grad_norm": 1.406972050666809,
        "learning_rate": 2.958366693354684e-05,
        "loss": 0.3969,
        "step": 1040
    },
    {
        "epoch": 0.8339952343129468,
        "grad_norm": 1.0272620916366577,
        "learning_rate": 2.9383506805444355e-05,
        "loss": 0.3502,
        "step": 1050
    },
    {
        "epoch": 0.8419380460683081,
        "grad_norm": 1.3506139516830444,
        "learning_rate": 2.9183346677341878e-05,
        "loss": 0.365,
        "step": 1060
    },
    {
        "epoch": 0.8498808578236696,
        "grad_norm": 1.3529160022735596,
        "learning_rate": 2.8983186549239394e-05,
        "loss": 0.3713,
        "step": 1070
    },
    {
        "epoch": 0.857823669579031,
        "grad_norm": 1.249479055404663,
        "learning_rate": 2.878302642113691e-05,
        "loss": 0.341,
        "step": 1080
    },
    {
        "epoch": 0.8657664813343924,
        "grad_norm": 1.45055091381073,
        "learning_rate": 2.8582866293034427e-05,
        "loss": 0.3356,
        "step": 1090
    },
    {
        "epoch": 0.8737092930897538,
        "grad_norm": 1.3259459733963013,
        "learning_rate": 2.838270616493195e-05,
        "loss": 0.3289,
        "step": 1100
    },
    {
        "epoch": 0.8816521048451151,
        "grad_norm": 1.0786813497543335,
        "learning_rate": 2.8182546036829466e-05,
        "loss": 0.3738,
        "step": 1110
    },
    {
        "epoch": 0.8895949166004765,
        "grad_norm": 1.6728609800338745,
        "learning_rate": 2.7982385908726982e-05,
        "loss": 0.3407,
        "step": 1120
    },
    {
        "epoch": 0.897537728355838,
        "grad_norm": 1.5370147228240967,
        "learning_rate": 2.77822257806245e-05,
        "loss": 0.3856,
        "step": 1130
    },
    {
        "epoch": 0.9054805401111994,
        "grad_norm": 1.7124013900756836,
        "learning_rate": 2.758206565252202e-05,
        "loss": 0.3562,
        "step": 1140
    },
    {
        "epoch": 0.9134233518665608,
        "grad_norm": 0.888820469379425,
        "learning_rate": 2.7381905524419538e-05,
        "loss": 0.3876,
        "step": 1150
    },
    {
        "epoch": 0.9213661636219221,
        "grad_norm": 1.335111141204834,
        "learning_rate": 2.7181745396317054e-05,
        "loss": 0.3218,
        "step": 1160
    },
    {
        "epoch": 0.9293089753772835,
        "grad_norm": 1.5080718994140625,
        "learning_rate": 2.698158526821457e-05,
        "loss": 0.3654,
        "step": 1170
    },
    {
        "epoch": 0.937251787132645,
        "grad_norm": 1.28183114528656,
        "learning_rate": 2.6781425140112093e-05,
        "loss": 0.3596,
        "step": 1180
    },
    {
        "epoch": 0.9451945988880064,
        "grad_norm": 1.5298354625701904,
        "learning_rate": 2.658126501200961e-05,
        "loss": 0.3641,
        "step": 1190
    },
    {
        "epoch": 0.9531374106433678,
        "grad_norm": 1.4167745113372803,
        "learning_rate": 2.6381104883907125e-05,
        "loss": 0.4094,
        "step": 1200
    },
    {
        "epoch": 0.9610802223987291,
        "grad_norm": 1.463940143585205,
        "learning_rate": 2.618094475580464e-05,
        "loss": 0.2782,
        "step": 1210
    },
    {
        "epoch": 0.9690230341540905,
        "grad_norm": 1.2159583568572998,
        "learning_rate": 2.5980784627702165e-05,
        "loss": 0.3799,
        "step": 1220
    },
    {
        "epoch": 0.9769658459094519,
        "grad_norm": 1.2643537521362305,
        "learning_rate": 2.578062449959968e-05,
        "loss": 0.3645,
        "step": 1230
    },
    {
        "epoch": 0.9849086576648134,
        "grad_norm": 1.228064775466919,
        "learning_rate": 2.5580464371497197e-05,
        "loss": 0.368,
        "step": 1240
    },
    {
        "epoch": 0.9928514694201748,
        "grad_norm": 0.9801463484764099,
        "learning_rate": 2.5380304243394713e-05,
        "loss": 0.4204,
        "step": 1250
    },
    {
        "epoch": 1.0007942811755361,
        "grad_norm": 0.8195188045501709,
        "learning_rate": 2.5180144115292236e-05,
        "loss": 0.3318,
        "step": 1260
    },
    {
        "epoch": 1.0087370929308976,
        "grad_norm": 1.823484182357788,
        "learning_rate": 2.4979983987189752e-05,
        "loss": 0.2206,
        "step": 1270
    },
    {
        "epoch": 1.016679904686259,
        "grad_norm": 1.0415325164794922,
        "learning_rate": 2.477982385908727e-05,
        "loss": 0.2056,
        "step": 1280
    },
    {
        "epoch": 1.0246227164416204,
        "grad_norm": 1.032935380935669,
        "learning_rate": 2.4579663730984788e-05,
        "loss": 0.2245,
        "step": 1290
    },
    {
        "epoch": 1.0325655281969817,
        "grad_norm": 1.263712763786316,
        "learning_rate": 2.4379503602882305e-05,
        "loss": 0.3639,
        "step": 1300
    },
    {
        "epoch": 1.0405083399523432,
        "grad_norm": 1.1809966564178467,
        "learning_rate": 2.4179343474779824e-05,
        "loss": 0.2127,
        "step": 1310
    },
    {
        "epoch": 1.0484511517077044,
        "grad_norm": 1.4427802562713623,
        "learning_rate": 2.397918334667734e-05,
        "loss": 0.2321,
        "step": 1320
    },
    {
        "epoch": 1.056393963463066,
        "grad_norm": 1.3548920154571533,
        "learning_rate": 2.377902321857486e-05,
        "loss": 0.2835,
        "step": 1330
    },
    {
        "epoch": 1.0643367752184274,
        "grad_norm": 1.1058413982391357,
        "learning_rate": 2.357886309047238e-05,
        "loss": 0.2045,
        "step": 1340
    },
    {
        "epoch": 1.0722795869737887,
        "grad_norm": 1.1596648693084717,
        "learning_rate": 2.3378702962369896e-05,
        "loss": 0.2879,
        "step": 1350
    },
    {
        "epoch": 1.0802223987291502,
        "grad_norm": 1.2991454601287842,
        "learning_rate": 2.3178542834267415e-05,
        "loss": 0.2226,
        "step": 1360
    },
    {
        "epoch": 1.0881652104845114,
        "grad_norm": 1.1914236545562744,
        "learning_rate": 2.297838270616493e-05,
        "loss": 0.2307,
        "step": 1370
    },
    {
        "epoch": 1.096108022239873,
        "grad_norm": 1.118756890296936,
        "learning_rate": 2.277822257806245e-05,
        "loss": 0.24,
        "step": 1380
    },
    {
        "epoch": 1.1040508339952344,
        "grad_norm": 1.2613834142684937,
        "learning_rate": 2.257806244995997e-05,
        "loss": 0.219,
        "step": 1390
    },
    {
        "epoch": 1.1119936457505957,
        "grad_norm": 1.1882338523864746,
        "learning_rate": 2.2377902321857487e-05,
        "loss": 0.2308,
        "step": 1400
    },
    {
        "epoch": 1.1199364575059572,
        "grad_norm": 1.3753811120986938,
        "learning_rate": 2.2177742193755007e-05,
        "loss": 0.2561,
        "step": 1410
    },
    {
        "epoch": 1.1278792692613184,
        "grad_norm": 1.4088361263275146,
        "learning_rate": 2.1977582065652523e-05,
        "loss": 0.2635,
        "step": 1420
    },
    {
        "epoch": 1.13582208101668,
        "grad_norm": 0.9582026600837708,
        "learning_rate": 2.1777421937550042e-05,
        "loss": 0.2349,
        "step": 1430
    },
    {
        "epoch": 1.1437648927720412,
        "grad_norm": 1.162133812904358,
        "learning_rate": 2.1577261809447562e-05,
        "loss": 0.2248,
        "step": 1440
    },
    {
        "epoch": 1.1517077045274027,
        "grad_norm": 0.8501204252243042,
        "learning_rate": 2.1377101681345078e-05,
        "loss": 0.2274,
        "step": 1450
    },
    {
        "epoch": 1.1596505162827642,
        "grad_norm": 1.4124239683151245,
        "learning_rate": 2.1176941553242598e-05,
        "loss": 0.2091,
        "step": 1460
    },
    {
        "epoch": 1.1675933280381254,
        "grad_norm": 1.0485950708389282,
        "learning_rate": 2.0976781425140114e-05,
        "loss": 0.2423,
        "step": 1470
    },
    {
        "epoch": 1.175536139793487,
        "grad_norm": 1.5922497510910034,
        "learning_rate": 2.0776621297037634e-05,
        "loss": 0.284,
        "step": 1480
    },
    {
        "epoch": 1.1834789515488482,
        "grad_norm": 0.8249122500419617,
        "learning_rate": 2.057646116893515e-05,
        "loss": 0.2346,
        "step": 1490
    },
    {
        "epoch": 1.1914217633042097,
        "grad_norm": 1.2339391708374023,
        "learning_rate": 2.037630104083267e-05,
        "loss": 0.2418,
        "step": 1500
    },
    {
        "epoch": 1.1993645750595712,
        "grad_norm": 1.1854130029678345,
        "learning_rate": 2.0176140912730186e-05,
        "loss": 0.2311,
        "step": 1510
    },
    {
        "epoch": 1.2073073868149324,
        "grad_norm": 1.3776695728302002,
        "learning_rate": 1.9975980784627705e-05,
        "loss": 0.227,
        "step": 1520
    },
    {
        "epoch": 1.215250198570294,
        "grad_norm": 1.2440232038497925,
        "learning_rate": 1.977582065652522e-05,
        "loss": 0.2669,
        "step": 1530
    },
    {
        "epoch": 1.2231930103256552,
        "grad_norm": 1.050183892250061,
        "learning_rate": 1.957566052842274e-05,
        "loss": 0.2065,
        "step": 1540
    },
    {
        "epoch": 1.2311358220810167,
        "grad_norm": 1.1961755752563477,
        "learning_rate": 1.9375500400320257e-05,
        "loss": 0.2504,
        "step": 1550
    },
    {
        "epoch": 1.2390786338363782,
        "grad_norm": 1.481187105178833,
        "learning_rate": 1.9175340272217777e-05,
        "loss": 0.218,
        "step": 1560
    },
    {
        "epoch": 1.2470214455917394,
        "grad_norm": 1.3450732231140137,
        "learning_rate": 1.8975180144115293e-05,
        "loss": 0.29,
        "step": 1570
    },
    {
        "epoch": 1.254964257347101,
        "grad_norm": 1.3130871057510376,
        "learning_rate": 1.8775020016012813e-05,
        "loss": 0.2292,
        "step": 1580
    },
    {
        "epoch": 1.2629070691024622,
        "grad_norm": 1.0688080787658691,
        "learning_rate": 1.857485988791033e-05,
        "loss": 0.2447,
        "step": 1590
    },
    {
        "epoch": 1.2708498808578237,
        "grad_norm": 0.8136557936668396,
        "learning_rate": 1.837469975980785e-05,
        "loss": 0.2552,
        "step": 1600
    },
    {
        "epoch": 1.2787926926131852,
        "grad_norm": 1.3169889450073242,
        "learning_rate": 1.8174539631705365e-05,
        "loss": 0.2061,
        "step": 1610
    },
    {
        "epoch": 1.2867355043685464,
        "grad_norm": 0.974726676940918,
        "learning_rate": 1.7974379503602884e-05,
        "loss": 0.1923,
        "step": 1620
    },
    {
        "epoch": 1.294678316123908,
        "grad_norm": 0.9403039813041687,
        "learning_rate": 1.77742193755004e-05,
        "loss": 0.2339,
        "step": 1630
    },
    {
        "epoch": 1.3026211278792692,
        "grad_norm": 1.7418628931045532,
        "learning_rate": 1.757405924739792e-05,
        "loss": 0.2509,
        "step": 1640
    },
    {
        "epoch": 1.3105639396346307,
        "grad_norm": 1.4986118078231812,
        "learning_rate": 1.7373899119295436e-05,
        "loss": 0.2323,
        "step": 1650
    },
    {
        "epoch": 1.3185067513899922,
        "grad_norm": 1.5175461769104004,
        "learning_rate": 1.7173738991192956e-05,
        "loss": 0.2236,
        "step": 1660
    },
    {
        "epoch": 1.3264495631453534,
        "grad_norm": 1.1990858316421509,
        "learning_rate": 1.6973578863090472e-05,
        "loss": 0.2086,
        "step": 1670
    },
    {
        "epoch": 1.3343923749007147,
        "grad_norm": 1.097233533859253,
        "learning_rate": 1.6773418734987992e-05,
        "loss": 0.2265,
        "step": 1680
    },
    {
        "epoch": 1.3423351866560762,
        "grad_norm": 1.1071515083312988,
        "learning_rate": 1.6573258606885508e-05,
        "loss": 0.1922,
        "step": 1690
    },
    {
        "epoch": 1.3502779984114377,
        "grad_norm": 1.0670586824417114,
        "learning_rate": 1.6373098478783028e-05,
        "loss": 0.2309,
        "step": 1700
    },
    {
        "epoch": 1.358220810166799,
        "grad_norm": 0.8552796244621277,
        "learning_rate": 1.6172938350680544e-05,
        "loss": 0.2204,
        "step": 1710
    },
    {
        "epoch": 1.3661636219221605,
        "grad_norm": 0.84673672914505,
        "learning_rate": 1.5972778222578063e-05,
        "loss": 0.1402,
        "step": 1720
    },
    {
        "epoch": 1.3741064336775217,
        "grad_norm": 1.0620743036270142,
        "learning_rate": 1.577261809447558e-05,
        "loss": 0.2205,
        "step": 1730
    },
    {
        "epoch": 1.3820492454328832,
        "grad_norm": 0.8560266494750977,
        "learning_rate": 1.55724579663731e-05,
        "loss": 0.1766,
        "step": 1740
    },
    {
        "epoch": 1.3899920571882447,
        "grad_norm": 1.1695488691329956,
        "learning_rate": 1.5372297838270615e-05,
        "loss": 0.2607,
        "step": 1750
    },
    {
        "epoch": 1.397934868943606,
        "grad_norm": 0.9222517013549805,
        "learning_rate": 1.5172137710168135e-05,
        "loss": 0.192,
        "step": 1760
    },
    {
        "epoch": 1.4058776806989675,
        "grad_norm": 1.2762410640716553,
        "learning_rate": 1.4971977582065653e-05,
        "loss": 0.2001,
        "step": 1770
    },
    {
        "epoch": 1.4138204924543287,
        "grad_norm": 1.1966218948364258,
        "learning_rate": 1.477181745396317e-05,
        "loss": 0.2071,
        "step": 1780
    },
    {
        "epoch": 1.4217633042096902,
        "grad_norm": 0.8758549690246582,
        "learning_rate": 1.4571657325860689e-05,
        "loss": 0.2039,
        "step": 1790
    },
    {
        "epoch": 1.4297061159650517,
        "grad_norm": 1.5960050821304321,
        "learning_rate": 1.4371497197758208e-05,
        "loss": 0.2257,
        "step": 1800
    },
    {
        "epoch": 1.437648927720413,
        "grad_norm": 1.053958773612976,
        "learning_rate": 1.4171337069655724e-05,
        "loss": 0.2625,
        "step": 1810
    },
    {
        "epoch": 1.4455917394757745,
        "grad_norm": 1.049627423286438,
        "learning_rate": 1.3971176941553244e-05,
        "loss": 0.1995,
        "step": 1820
    },
    {
        "epoch": 1.4535345512311357,
        "grad_norm": 0.9534332156181335,
        "learning_rate": 1.377101681345076e-05,
        "loss": 0.1904,
        "step": 1830
    },
    {
        "epoch": 1.4614773629864972,
        "grad_norm": 1.313855528831482,
        "learning_rate": 1.357085668534828e-05,
        "loss": 0.1897,
        "step": 1840
    },
    {
        "epoch": 1.4694201747418587,
        "grad_norm": 1.1624023914337158,
        "learning_rate": 1.3370696557245796e-05,
        "loss": 0.2283,
        "step": 1850
    },
    {
        "epoch": 1.47736298649722,
        "grad_norm": 1.230964183807373,
        "learning_rate": 1.3170536429143316e-05,
        "loss": 0.1913,
        "step": 1860
    },
    {
        "epoch": 1.4853057982525815,
        "grad_norm": 1.2776503562927246,
        "learning_rate": 1.2970376301040832e-05,
        "loss": 0.2649,
        "step": 1870
    },
    {
        "epoch": 1.4932486100079427,
        "grad_norm": 0.8666617274284363,
        "learning_rate": 1.2770216172938352e-05,
        "loss": 0.2444,
        "step": 1880
    },
    {
        "epoch": 1.5011914217633042,
        "grad_norm": 1.6239995956420898,
        "learning_rate": 1.2570056044835871e-05,
        "loss": 0.2111,
        "step": 1890
    },
    {
        "epoch": 1.5091342335186657,
        "grad_norm": 0.8591787815093994,
        "learning_rate": 1.2369895916733387e-05,
        "loss": 0.1761,
        "step": 1900
    },
    {
        "epoch": 1.517077045274027,
        "grad_norm": 1.0996075868606567,
        "learning_rate": 1.2169735788630905e-05,
        "loss": 0.2017,
        "step": 1910
    },
    {
        "epoch": 1.5250198570293882,
        "grad_norm": 1.5945234298706055,
        "learning_rate": 1.1969575660528423e-05,
        "loss": 0.2343,
        "step": 1920
    },
    {
        "epoch": 1.5329626687847497,
        "grad_norm": 0.6763985753059387,
        "learning_rate": 1.1769415532425941e-05,
        "loss": 0.21,
        "step": 1930
    },
    {
        "epoch": 1.5409054805401112,
        "grad_norm": 1.1864359378814697,
        "learning_rate": 1.1569255404323459e-05,
        "loss": 0.2449,
        "step": 1940
    },
    {
        "epoch": 1.5488482922954727,
        "grad_norm": 1.236258625984192,
        "learning_rate": 1.1369095276220977e-05,
        "loss": 0.1863,
        "step": 1950
    },
    {
        "epoch": 1.556791104050834,
        "grad_norm": 1.248085856437683,
        "learning_rate": 1.1168935148118495e-05,
        "loss": 0.1807,
        "step": 1960
    },
    {
        "epoch": 1.5647339158061953,
        "grad_norm": 0.9720270037651062,
        "learning_rate": 1.0968775020016013e-05,
        "loss": 0.1837,
        "step": 1970
    },
    {
        "epoch": 1.5726767275615567,
        "grad_norm": 1.0385397672653198,
        "learning_rate": 1.076861489191353e-05,
        "loss": 0.155,
        "step": 1980
    },
    {
        "epoch": 1.5806195393169182,
        "grad_norm": 1.5808875560760498,
        "learning_rate": 1.0568454763811048e-05,
        "loss": 0.2382,
        "step": 1990
    },
    {
        "epoch": 1.5885623510722797,
        "grad_norm": 0.6122334003448486,
        "learning_rate": 1.0368294635708566e-05,
        "loss": 0.1923,
        "step": 2000
    },
    {
        "epoch": 1.596505162827641,
        "grad_norm": 1.0357941389083862,
        "learning_rate": 1.0168134507606084e-05,
        "loss": 0.1761,
        "step": 2010
    },
    {
        "epoch": 1.6044479745830023,
        "grad_norm": 0.9493880867958069,
        "learning_rate": 9.967974379503602e-06,
        "loss": 0.2514,
        "step": 2020
    },
    {
        "epoch": 1.6123907863383637,
        "grad_norm": 1.359230875968933,
        "learning_rate": 9.76781425140112e-06,
        "loss": 0.2085,
        "step": 2030
    },
    {
        "epoch": 1.6203335980937252,
        "grad_norm": 1.2022507190704346,
        "learning_rate": 9.56765412329864e-06,
        "loss": 0.2306,
        "step": 2040
    },
    {
        "epoch": 1.6282764098490867,
        "grad_norm": 1.2366902828216553,
        "learning_rate": 9.367493995196158e-06,
        "loss": 0.2059,
        "step": 2050
    },
    {
        "epoch": 1.636219221604448,
        "grad_norm": 1.1091228723526,
        "learning_rate": 9.167333867093676e-06,
        "loss": 0.2868,
        "step": 2060
    },
    {
        "epoch": 1.6441620333598093,
        "grad_norm": 0.7073994874954224,
        "learning_rate": 8.967173738991193e-06,
        "loss": 0.1781,
        "step": 2070
    },
    {
        "epoch": 1.6521048451151708,
        "grad_norm": 1.0974613428115845,
        "learning_rate": 8.767013610888711e-06,
        "loss": 0.1817,
        "step": 2080
    },
    {
        "epoch": 1.6600476568705322,
        "grad_norm": 1.284132957458496,
        "learning_rate": 8.56685348278623e-06,
        "loss": 0.1877,
        "step": 2090
    },
    {
        "epoch": 1.6679904686258937,
        "grad_norm": 0.9180740118026733,
        "learning_rate": 8.366693354683747e-06,
        "loss": 0.2052,
        "step": 2100
    },
    {
        "epoch": 1.675933280381255,
        "grad_norm": 0.9081233739852905,
        "learning_rate": 8.166533226581267e-06,
        "loss": 0.2068,
        "step": 2110
    },
    {
        "epoch": 1.6838760921366163,
        "grad_norm": 0.997587263584137,
        "learning_rate": 7.966373098478785e-06,
        "loss": 0.1914,
        "step": 2120
    },
    {
        "epoch": 1.6918189038919778,
        "grad_norm": 0.724139392375946,
        "learning_rate": 7.766212970376303e-06,
        "loss": 0.219,
        "step": 2130
    },
    {
        "epoch": 1.6997617156473392,
        "grad_norm": 0.9354813694953918,
        "learning_rate": 7.56605284227382e-06,
        "loss": 0.251,
        "step": 2140
    },
    {
        "epoch": 1.7077045274027005,
        "grad_norm": 0.8505538702011108,
        "learning_rate": 7.365892714171338e-06,
        "loss": 0.1448,
        "step": 2150
    },
    {
        "epoch": 1.715647339158062,
        "grad_norm": 1.656431794166565,
        "learning_rate": 7.165732586068856e-06,
        "loss": 0.2294,
        "step": 2160
    },
    {
        "epoch": 1.7235901509134233,
        "grad_norm": 1.0915695428848267,
        "learning_rate": 6.965572457966374e-06,
        "loss": 0.202,
        "step": 2170
    },
    {
        "epoch": 1.7315329626687848,
        "grad_norm": 1.1520870923995972,
        "learning_rate": 6.765412329863892e-06,
        "loss": 0.1463,
        "step": 2180
    },
    {
        "epoch": 1.7394757744241462,
        "grad_norm": 0.7985594868659973,
        "learning_rate": 6.56525220176141e-06,
        "loss": 0.136,
        "step": 2190
    },
    {
        "epoch": 1.7474185861795075,
        "grad_norm": 0.8530821800231934,
        "learning_rate": 6.365092073658928e-06,
        "loss": 0.1813,
        "step": 2200
    },
    {
        "epoch": 1.7553613979348688,
        "grad_norm": 0.901068925857544,
        "learning_rate": 6.164931945556445e-06,
        "loss": 0.2429,
        "step": 2210
    },
    {
        "epoch": 1.7633042096902303,
        "grad_norm": 0.6556864380836487,
        "learning_rate": 5.964771817453964e-06,
        "loss": 0.1687,
        "step": 2220
    },
    {
        "epoch": 1.7712470214455918,
        "grad_norm": 0.8112409710884094,
        "learning_rate": 5.764611689351482e-06,
        "loss": 0.1511,
        "step": 2230
    },
    {
        "epoch": 1.7791898332009533,
        "grad_norm": 0.6735513210296631,
        "learning_rate": 5.5644515612489995e-06,
        "loss": 0.2379,
        "step": 2240
    },
    {
        "epoch": 1.7871326449563145,
        "grad_norm": 1.2369002103805542,
        "learning_rate": 5.364291433146517e-06,
        "loss": 0.1963,
        "step": 2250
    },
    {
        "epoch": 1.7950754567116758,
        "grad_norm": 1.3022949695587158,
        "learning_rate": 5.164131305044035e-06,
        "loss": 0.2076,
        "step": 2260
    },
    {
        "epoch": 1.8030182684670373,
        "grad_norm": 0.8261489868164062,
        "learning_rate": 4.963971176941554e-06,
        "loss": 0.2389,
        "step": 2270
    },
    {
        "epoch": 1.8109610802223988,
        "grad_norm": 1.1718087196350098,
        "learning_rate": 4.763811048839072e-06,
        "loss": 0.2083,
        "step": 2280
    },
    {
        "epoch": 1.8189038919777603,
        "grad_norm": 1.2880489826202393,
        "learning_rate": 4.56365092073659e-06,
        "loss": 0.1783,
        "step": 2290
    },
    {
        "epoch": 1.8268467037331215,
        "grad_norm": 1.0391664505004883,
        "learning_rate": 4.363490792634108e-06,
        "loss": 0.1784,
        "step": 2300
    },
    {
        "epoch": 1.8347895154884828,
        "grad_norm": 0.7738174796104431,
        "learning_rate": 4.163330664531626e-06,
        "loss": 0.2426,
        "step": 2310
    },
    {
        "epoch": 1.8427323272438443,
        "grad_norm": 1.4582723379135132,
        "learning_rate": 3.963170536429144e-06,
        "loss": 0.1982,
        "step": 2320
    },
    {
        "epoch": 1.8506751389992058,
        "grad_norm": 1.2069509029388428,
        "learning_rate": 3.7630104083266615e-06,
        "loss": 0.2042,
        "step": 2330
    },
    {
        "epoch": 1.8586179507545673,
        "grad_norm": 1.0194263458251953,
        "learning_rate": 3.5628502802241794e-06,
        "loss": 0.215,
        "step": 2340
    },
    {
        "epoch": 1.8665607625099285,
        "grad_norm": 1.129589557647705,
        "learning_rate": 3.3626901521216973e-06,
        "loss": 0.1558,
        "step": 2350
    },
    {
        "epoch": 1.8745035742652898,
        "grad_norm": 1.135498046875,
        "learning_rate": 3.1625300240192156e-06,
        "loss": 0.1853,
        "step": 2360
    },
    {
        "epoch": 1.8824463860206513,
        "grad_norm": 0.8077393770217896,
        "learning_rate": 2.9623698959167336e-06,
        "loss": 0.1965,
        "step": 2370
    },
    {
        "epoch": 1.8903891977760128,
        "grad_norm": 1.17453134059906,
        "learning_rate": 2.7622097678142515e-06,
        "loss": 0.1871,
        "step": 2380
    },
    {
        "epoch": 1.8983320095313743,
        "grad_norm": 1.2962125539779663,
        "learning_rate": 2.5620496397117694e-06,
        "loss": 0.1924,
        "step": 2390
    },
    {
        "epoch": 1.9062748212867355,
        "grad_norm": 1.0160712003707886,
        "learning_rate": 2.3618895116092877e-06,
        "loss": 0.2574,
        "step": 2400
    },
    {
        "epoch": 1.9142176330420968,
        "grad_norm": 1.0221679210662842,
        "learning_rate": 2.1617293835068056e-06,
        "loss": 0.1811,
        "step": 2410
    },
    {
        "epoch": 1.9221604447974583,
        "grad_norm": 1.1620889902114868,
        "learning_rate": 1.9615692554043235e-06,
        "loss": 0.1947,
        "step": 2420
    },
    {
        "epoch": 1.9301032565528198,
        "grad_norm": 0.7165130376815796,
        "learning_rate": 1.7614091273018416e-06,
        "loss": 0.1767,
        "step": 2430
    },
    {
        "epoch": 1.938046068308181,
        "grad_norm": 1.2101482152938843,
        "learning_rate": 1.5612489991993595e-06,
        "loss": 0.2138,
        "step": 2440
    },
    {
        "epoch": 1.9459888800635425,
        "grad_norm": 0.8484862446784973,
        "learning_rate": 1.3610888710968776e-06,
        "loss": 0.1749,
        "step": 2450
    },
    {
        "epoch": 1.9539316918189038,
        "grad_norm": 0.950000524520874,
        "learning_rate": 1.1609287429943956e-06,
        "loss": 0.2653,
        "step": 2460
    },
    {
        "epoch": 1.9618745035742653,
        "grad_norm": 0.7832910418510437,
        "learning_rate": 9.607686148919135e-07,
        "loss": 0.1409,
        "step": 2470
    },
    {
        "epoch": 1.9698173153296268,
        "grad_norm": 0.9613577127456665,
        "learning_rate": 7.606084867894316e-07,
        "loss": 0.2041,
        "step": 2480
    },
    {
        "epoch": 1.977760127084988,
        "grad_norm": 0.747429609298706,
        "learning_rate": 5.604483586869496e-07,
        "loss": 0.1823,
        "step": 2490
    },
    {
        "epoch": 1.9857029388403493,
        "grad_norm": 1.1521140336990356,
        "learning_rate": 3.602882305844676e-07,
        "loss": 0.1664,
        "step": 2500
    },
    {
        "epoch": 1.9936457505957108,
        "grad_norm": 0.9599699974060059,
        "learning_rate": 1.6012810248198559e-07,
        "loss": 0.1839,
        "step": 2510
    }
]